# pipeline/processor.py

from __future__ import annotations

import json
from pprint import pprint
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

from config.settings import STATE_STORE_FILE, BASE_DIR, TEMP_DIR, AI_RESULTS_DIR, EXPORT_DIR
from core.drive_client import DriveClient
from core.state_store import StateStore
from core.folder_context import FolderContext
from core.ai_analyzer import call_openai_for_product
from core.product_normalizer import normalize_product
from core.product_schema import ProductDraft
from core.etsy_exporter import export_products_to_csv, export_products_to_excel


def parse_folder_name(name: str) -> Dict[str, Any]:
    """
    æŒ‰çº¦å®šè§£ææ–‡ä»¶å¤¹å:
    {product_type}-{materials}-{series}_{price}

    ä¾‹: 'earring-ç™½èŠ·-å®é™ç³»åˆ—_25'
    """
    name = name.strip()

    # å…ˆæŒ‰ '_' æ‹†å‡ºä»·æ ¼éƒ¨åˆ†
    base_part, sep, price_part = name.rpartition("_")
    price: float | None = None
    if sep:  # æ‰¾åˆ°äº† '_'
        try:
            price = float(price_part)
        except ValueError:
            price = None
    else:
        base_part = name  # æ²¡æœ‰ '_', å…¨éƒ¨ä½œä¸ºå‰åŠéƒ¨åˆ†

    # å†æŒ‰ '-' æ‹† product_type / materials / series
    # æœ€å¤šåˆ†æˆ 3 æ®µï¼Œå¤šå‡ºæ¥çš„éƒ½è¿›æœ€åä¸€æ®µ
    parts = base_part.split("-", 2)
    product_type = parts[0].strip() if len(parts) > 0 else ""
    materials_raw = parts[1].strip() if len(parts) > 1 else ""
    series = parts[2].strip() if len(parts) > 2 else ""

    return {
        "product_type": product_type,
        "materials_raw": materials_raw,
        "series": series,
        "price": price,
    }


def classify_files(files: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
    """
    æ ¹æ® mimeType æŠŠæ–‡ä»¶åˆ†æˆå›¾ç‰‡ / å…¶ä»–
    """
    images: List[Dict[str, Any]] = []
    others: List[Dict[str, Any]] = []

    for f in files:
        mime = f.get("mimeType", "")
        if mime.startswith("image/"):
            images.append(f)
        else:
            others.append(f)

    return {"images": images, "others": others}


def download_main_image_debug(
    drive: DriveClient,
    folder_id: str,
    folder_name: str,
    first_image: Dict[str, Any],
) -> Path:
    """
    è°ƒè¯•ç”¨ï¼šä¸‹è½½ä¸»å›¾åˆ°æœ¬åœ°ï¼Œçœ‹è·¯å¾„æ˜¯å¦æ­£å¸¸ã€‚
    downloads/{folder_id}/{filename}
    """
    print(f"  [è°ƒè¯•] download_main_image_debug å‡½æ•°è¢«è°ƒç”¨")
    print(f"  [è°ƒè¯•] folder_id: {folder_id}, folder_name: {folder_name}")
    print(f"  [è°ƒè¯•] first_image: {first_image}")
    
    download_dir = BASE_DIR / "downloads" / folder_id
    dest_path = download_dir / first_image["name"]
    print(f"  [è°ƒè¯•] ç›®æ ‡è·¯å¾„: {dest_path}")
    
    print(f"  [è°ƒè¯•] å¼€å§‹è°ƒç”¨ drive.download_file...")
    drive.download_file(first_image["id"], dest_path)
    print(f"  âœ… ä¸»å›¾å·²ä¸‹è½½åˆ°: {dest_path}")
    return dest_path


def build_folder_context(
    folder_meta: Dict[str, Any], 
    drive: DriveClient
) -> tuple[FolderContext, Path]:
    """
    æ ¹æ® folder_meta æ„å»º FolderContext å¹¶ä¸‹è½½ä¸»å›¾ã€‚
    
    Args:
        folder_meta: åŒ…å« id, name, createdTime çš„æ–‡ä»¶å¤¹å…ƒæ•°æ®
        drive: DriveClient å®ä¾‹
    
    Returns:
        (FolderContext, main_image_path) å…ƒç»„
    """
    folder_id = folder_meta["id"]
    folder_name = folder_meta["name"]
    created_time = folder_meta.get("createdTime", "")

    # 1. åˆ—å‡ºæ–‡ä»¶ï¼Œæ‰¾åˆ°ç¬¬ä¸€å¼ å›¾ç‰‡ä½œä¸ºä¸»å›¾
    files = drive.list_files_in_folder(folder_id)
    if not files:
        raise RuntimeError(f"æ–‡ä»¶å¤¹ {folder_name} ä¸­æ²¡æœ‰æ–‡ä»¶ã€‚")

    classified = classify_files(files)
    image_files = classified["images"]
    other_files = classified["others"]

    if not image_files:
        raise RuntimeError(f"æ–‡ä»¶å¤¹ {folder_name} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ã€‚")

    main_image_file = image_files[0]

    # 2. ä¸‹è½½ä¸»å›¾åˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•
    # ä½¿ç”¨ä¸´æ—¶ç›®å½•ï¼Œæ–‡ä»¶åä½¿ç”¨ folder_id å’ŒåŸæ–‡ä»¶å
    tmp_dir = TEMP_DIR / "images"
    tmp_dir.mkdir(parents=True, exist_ok=True)
    
    # è·å–åŸæ–‡ä»¶æ‰©å±•åï¼Œå¦‚æœæ²¡æœ‰åˆ™é»˜è®¤ .jpg
    original_name = main_image_file.get("name", "image")
    original_ext = Path(original_name).suffix or ".jpg"
    dest_path = tmp_dir / f"{folder_id}_main{original_ext}"

    print(f"  ğŸ“¥ ä¸‹è½½ä¸»å›¾: {main_image_file['name']} -> {dest_path}")
    drive.download_file(main_image_file["id"], dest_path)

    # 3. è§£ææ–‡ä»¶å¤¹å
    parsed = parse_folder_name(folder_name)
    
    # 4. æŸ¥æ‰¾å¹¶è¯»å– note.txtï¼ˆå¦‚æœæœ‰ï¼‰
    note_file = None
    note_text = ""
    for f in other_files:
        if f.get("name", "").lower() in ["note.txt", "notes.txt", "note"]:
            note_file = f
            # ä¸‹è½½å¹¶è¯»å– note.txt å†…å®¹
            note_path = tmp_dir / f"{folder_id}_note.txt"
            drive.download_file(f["id"], note_path)
            try:
                note_text = note_path.read_text(encoding="utf-8")
            except Exception as e:
                print(f"  âš ï¸ è¯»å– note.txt å¤±è´¥: {e}")
            break

    # 5. æ„å»º FolderContext
    ctx = FolderContext(
        folder_id=folder_id,
        folder_name=folder_name,
        created_time=created_time,
        product_type=parsed.get("product_type", ""),
        raw_materials_str=parsed.get("materials_raw", ""),
        series=parsed.get("series", ""),
        price_from_name=parsed.get("price"),  # parse_folder_name è¿”å›çš„æ˜¯ "price"
        image_files=image_files,
        note_file=note_file,
        other_files=other_files,
        note_text=note_text,
    )

    return ctx, dest_path


def process_new_folders_debug() -> None:
    """
    è°ƒè¯•ç‰ˆå¤„ç†å‡½æ•°ï¼š
    - è¯»å– state.json ä¸­ status == 'pending' çš„æ–‡ä»¶å¤¹
    - å¯¹æ¯ä¸ªæ–‡ä»¶å¤¹:
        * æ„é€  FolderContext
        * è°ƒç”¨ OpenAI ç”Ÿæˆå•†å“ JSON
        * è½¬æ¢ä¸º ProductDraft
        * æ”¶é›†æ‰€æœ‰äº§å“ç”¨äºå¯¼å‡º
    - æœ€åå¯¼å‡ºä¸º CSV/Excel æ–‡ä»¶
    """
    state = StateStore(STATE_STORE_FILE)
    drive = DriveClient()

    # è·å– pending çŠ¶æ€çš„æ–‡ä»¶å¤¹
    pending_records = state.list_unfinished_folders(status_filter=["pending"])
    if not pending_records:
        print("âœ… å½“å‰æ²¡æœ‰ pending çŠ¶æ€çš„æ–‡ä»¶å¤¹éœ€è¦å¤„ç†ã€‚")
        return

    print(f"ğŸ” å‘ç° {len(pending_records)} ä¸ª pending æ–‡ä»¶å¤¹ï¼Œå¼€å§‹å¤„ç†...\n")

    # æ”¶é›†æ‰€æœ‰å¤„ç†æˆåŠŸçš„äº§å“
    products_for_export: List[tuple[ProductDraft, List[Dict[str, Any]]]] = []

    for folder_id, rec in pending_records.items():
        folder_name = rec.get("name", "")
        print(f"\nğŸ—‚ å¤„ç†æ–‡ä»¶å¤¹: {folder_name} ({folder_id})")

        try:
            # ä» Drive è·å–æ–‡ä»¶å¤¹çš„å®Œæ•´ä¿¡æ¯ï¼ˆåŒ…æ‹¬ createdTimeï¼‰
            # æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦ä»çˆ¶ç›®å½•åˆ—è¡¨ä¸­æŸ¥æ‰¾è¿™ä¸ªæ–‡ä»¶å¤¹ï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨å·²çŸ¥ä¿¡æ¯
            # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨ state ä¸­å·²æœ‰çš„ä¿¡æ¯ï¼ŒcreatedTime å¯ä»¥ä» Drive è·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
            folder_meta = {
                "id": folder_id,
                "name": folder_name,
                "createdTime": rec.get("createdTime", ""),  # å¦‚æœ state ä¸­æ²¡æœ‰ï¼Œå°±ç•™ç©º
            }

            # æ„é€  FolderContext
            print("ğŸ“‚ æ„å»º FolderContext...")
            ctx, main_image_path = build_folder_context(folder_meta, drive)
            
            print("ğŸ“‚ è§£æåçš„ FolderContextï¼š")
            print(f"  - folder_id: {ctx.folder_id}")
            print(f"  - folder_name: {ctx.folder_name}")
            print(f"  - product_type: {ctx.product_type}")
            print(f"  - raw_materials_str: {ctx.raw_materials_str}")
            print(f"  - series: {ctx.series}")
            print(f"  - price_from_name: {ctx.price_from_name}")
            print(f"  - å›¾ç‰‡æ•°é‡: {len(ctx.image_files)}")
            print(f"  - ä¸»å›¾è·¯å¾„: {main_image_path}")

            # === è¿™é‡Œæ­£å¼è¿›å…¥ AI é˜¶æ®µ ===
            print("\nğŸ¤– è°ƒç”¨ OpenAI ç”Ÿæˆå•†å“ JSON...")
            ai_data = call_openai_for_product(ctx, main_image_path)
            
            print("\nâœ… OpenAI è¿”å› JSONï¼š")
            pprint(ai_data)

            # ä¿å­˜ AI è¿”å›çš„ JSON åˆ°æ–‡ä»¶
            ai_result_file = AI_RESULTS_DIR / f"{folder_id}.json"
            with ai_result_file.open("w", encoding="utf-8") as f:
                json.dump(ai_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ AI ç»“æœå·²ä¿å­˜åˆ°: {ai_result_file}")

            # === ä½¿ç”¨ normalizer è½¬æ¢ä¸º ProductDraft ===
            print("\nğŸ”§ ä½¿ç”¨ normalizer è½¬æ¢ä¸º ProductDraft...")
            final_product = normalize_product(ai_data, ctx)
            print("\nâœ… æœ€ç»ˆ ProductDraftï¼š")
            print(f"  ID: {final_product.id}")
            print(f"  æ ‡é¢˜: {final_product.title}")
            print(f"  ä»·æ ¼: {final_product.currency} {final_product.price}")
            print(f"  ç±»å‹: {final_product.product_type}")
            print(f"  ç³»åˆ—: {final_product.series}")
            print(f"  æ ‡ç­¾ ({len(final_product.tags)}): {', '.join(final_product.tags[:5])}{'...' if len(final_product.tags) > 5 else ''}")
            print(f"  ææ–™ ({len(final_product.materials)}): {', '.join(final_product.materials[:5])}{'...' if len(final_product.materials) > 5 else ''}")
            print(f"  é¢œè‰²: {', '.join(final_product.colors) if final_product.colors else 'N/A'}")
            print(f"  æè¿°é•¿åº¦: {len(final_product.description)} å­—ç¬¦")
            print(f"\nå®Œæ•´ ProductDraft å¯¹è±¡ï¼š")
            pprint(final_product)

            # æ”¶é›†äº§å“ç”¨äºå¯¼å‡ºï¼ˆåŒ…å«å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯ï¼‰
            products_for_export.append((final_product, ctx.image_files))

        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤¹ {folder_name} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue

        print("")  # ç©ºè¡Œåˆ†éš”ä¸€ä¸‹

    # === å¯¼å‡ºæ‰€æœ‰äº§å“ä¸º CSV/Excel ===
    if products_for_export:
        print("\n" + "=" * 60)
        print("å¯¼å‡º Etsy å¡«å†™è¡¨æ ¼")
        print("=" * 60)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å¯¼å‡º CSV
        csv_path = EXPORT_DIR / f"etsy_products_{timestamp}.csv"
        try:
            export_products_to_csv(products_for_export, csv_path)
            print(f"âœ… CSV æ–‡ä»¶å·²å¯¼å‡º: {csv_path}")
        except Exception as e:
            print(f"âŒ å¯¼å‡º CSV å¤±è´¥: {e}")
        
        # å¯¼å‡º Excelï¼ˆå¦‚æœå®‰è£…äº† openpyxlï¼‰
        excel_path = EXPORT_DIR / f"etsy_products_{timestamp}.xlsx"
        try:
            export_products_to_excel(products_for_export, excel_path)
            print(f"âœ… Excel æ–‡ä»¶å·²å¯¼å‡º: {excel_path}")
        except ImportError as e:
            print(f"âš ï¸  è·³è¿‡ Excel å¯¼å‡ºï¼ˆéœ€è¦å®‰è£… openpyxl: pip install openpyxlï¼‰")
        except Exception as e:
            print(f"âŒ å¯¼å‡º Excel å¤±è´¥: {e}")
        
        print(f"\nğŸ“‹ å…±å¯¼å‡º {len(products_for_export)} ä¸ªäº§å“")
        print(f"   æ–‡ä»¶ä½ç½®: {EXPORT_DIR}")
    else:
        print("\nâš ï¸  æ²¡æœ‰æˆåŠŸå¤„ç†çš„äº§å“ï¼Œæ— æ³•å¯¼å‡ºã€‚")
